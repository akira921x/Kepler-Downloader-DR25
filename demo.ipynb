{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kepler DR25 Downloader Demo\n",
    "\n",
    "This notebook demonstrates how to use the Kepler DR25 Downloader toolkit for downloading and filtering Kepler space telescope data from NASA's MAST archive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The toolkit provides two main scripts:\n",
    "\n",
    "1. **`get-kepler-dr25.py`** - Main downloader with DVT filtering\n",
    "2. **`filter-get-kepler-dr25.py`** - Universal filter with mode detection and conversion\n",
    "\n",
    "### Key Features:\n",
    "- Fast parallel downloading (15-20 KICs/minute)\n",
    "- ExoMiner format support (default) for ML frameworks\n",
    "- Standard MAST format option\n",
    "- DVT (Data Validation) file filtering\n",
    "- Redis-based buffering for reliability\n",
    "- Comprehensive health reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "assert sys.version_info >= (3, 7), \"Python 3.7+ is required\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check required packages\n",
    "import importlib\n",
    "\n",
    "required_packages = [\n",
    "    'pandas',\n",
    "    'numpy',\n",
    "    'astroquery',\n",
    "    'redis',\n",
    "    'requests',\n",
    "    'tqdm'\n",
    "]\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "        print(f\"✓ {package} is installed\")\n",
    "    except ImportError:\n",
    "        print(f\"✗ {package} is not installed. Please run: pip install {package}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check Redis connection\nimport redis\n\ntry:\n    r = redis.Redis(host='localhost', port=6379, db=0)\n    r.ping()\n    print(\"✓ Redis is running and accessible\")\nexcept Exception:\n    print(\"✗ Redis is not running. Please start Redis for optimal performance\")\n    print(\"  On macOS: brew services start redis\")\n    print(\"  On Linux: sudo systemctl start redis\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Download Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample CSV with a few KIC IDs\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create input directory if it doesn't exist\n",
    "os.makedirs('input', exist_ok=True)\n",
    "\n",
    "# Create a small test CSV with 5 KIC IDs\n",
    "test_kics = pd.DataFrame({\n",
    "    'kepid': [757450, 892772, 1161345, 1432214, 1725016]\n",
    "})\n",
    "\n",
    "test_csv_path = 'input/test_kics.csv'\n",
    "test_kics.to_csv(test_csv_path, index=False)\n",
    "print(f\"Created test CSV with {len(test_kics)} KIC IDs: {test_csv_path}\")\n",
    "print(test_kics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the downloader with ExoMiner format (default)\n",
    "!python get-kepler-dr25.py input/test_kics.csv --workers 2 --batch-size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output structure\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the latest job directory\n",
    "job_dirs = sorted(glob.glob('kepler_downloads/job-*'))\n",
    "if job_dirs:\n",
    "    latest_job = job_dirs[-1]\n",
    "    print(f\"Latest job: {latest_job}\")\n",
    "\n",
    "    # Show directory structure\n",
    "    for path in Path(latest_job).rglob('*.fits'):\n",
    "        print(f\"  {path.relative_to(latest_job)}\")\n",
    "else:\n",
    "    print(\"No job directories found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download with Standard MAST Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the downloader with Standard MAST format\n",
    "!python get-kepler-dr25.py input/test_kics.csv --no-exominer --workers 2 --batch-size 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter and Convert Between Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset CSV for filtering\n",
    "subset_kics = pd.DataFrame({\n",
    "    'kepid': [757450, 892772]  # Just 2 KICs from our original 5\n",
    "})\n",
    "\n",
    "subset_csv_path = 'input/subset_kics.csv'\n",
    "subset_kics.to_csv(subset_csv_path, index=False)\n",
    "print(f\"Created subset CSV with {len(subset_kics)} KIC IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter an existing job using the subset\n",
    "if job_dirs:\n",
    "    source_job = job_dirs[-1]\n",
    "    print(f\"Filtering from: {source_job}\")\n",
    "    !python filter-get-kepler-dr25.py --input-csv input/subset_kics.csv --source-job {source_job}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Health Report Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and display health report\n",
    "import os\n",
    "\n",
    "if job_dirs:\n",
    "    health_report_path = os.path.join(job_dirs[-1], 'health_check_report.txt')\n",
    "    if os.path.exists(health_report_path):\n",
    "        with open(health_report_path) as f:\n",
    "            print(f.read())\n",
    "    else:\n",
    "        print(\"Health report not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Database Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the download database\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if job_dirs:\n",
    "    db_path = os.path.join(job_dirs[-1], 'download_records.db')\n",
    "    if os.path.exists(db_path):\n",
    "        conn = sqlite3.connect(db_path)\n",
    "\n",
    "        # Get download statistics\n",
    "        df = pd.read_sql_query(\n",
    "            \"SELECT kic, success, files_downloaded, has_dvt FROM download_records\",\n",
    "            conn\n",
    "        )\n",
    "\n",
    "        print(\"Download Statistics:\")\n",
    "        print(f\"Total KICs: {len(df)}\")\n",
    "        print(f\"Successful: {df['success'].sum()}\")\n",
    "        print(f\"With DVT: {df['has_dvt'].sum()}\")\n",
    "        print(f\"Total files: {df['files_downloaded'].sum()}\")\n",
    "        print(\"\\nDetailed records:\")\n",
    "        print(df)\n",
    "\n",
    "        conn.close()\n",
    "    else:\n",
    "        print(\"Database not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Working with Sample Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine the sample KOI dataset\n",
    "koi_df = pd.read_csv('input_samples/cumulative_koi_2025.09.06_13.27.56.csv', comment='#')\n",
    "print(f\"KOI dataset: {len(koi_df)} entries\")\n",
    "print(f\"Columns: {list(koi_df.columns)[:5]}...\")  # Show first 5 columns\n",
    "print(\"\\nFirst 5 KIC IDs:\")\n",
    "print(koi_df['kepid'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine the sample TCE dataset\n",
    "tce_df = pd.read_csv('input_samples/q1_q17_dr25_tce_2025.09.06_13.29.19.csv', comment='#')\n",
    "print(f\"TCE dataset: {len(tce_df)} entries\")\n",
    "print(f\"Unique KICs: {tce_df['kepid'].nunique()}\")\n",
    "print(\"\\nFirst 5 KIC IDs:\")\n",
    "print(tce_df['kepid'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips and Best Practices\n",
    "\n",
    "1. **Start Small**: Test with a few KICs before downloading large datasets\n",
    "2. **Use Redis**: Ensures data integrity and allows recovery from interruptions\n",
    "3. **Monitor Progress**: Check the console output and health reports\n",
    "4. **ExoMiner vs Standard**: \n",
    "   - Use ExoMiner (default) for ML frameworks\n",
    "   - Use Standard (`--no-exominer`) for general analysis\n",
    "5. **Optimize Performance**:\n",
    "   - Increase workers for faster downloads: `--workers 8`\n",
    "   - Adjust batch size: `--batch-size 100`\n",
    "6. **Filter Smartly**: Use the filter script to extract subsets without re-downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up test files\n",
    "# Uncomment to remove test data\n",
    "# import shutil\n",
    "# if os.path.exists('input/test_kics.csv'):\n",
    "#     os.remove('input/test_kics.csv')\n",
    "# if os.path.exists('input/subset_kics.csv'):\n",
    "#     os.remove('input/subset_kics.csv')\n",
    "# print(\"Test files cleaned up\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}